{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from armscan_env.config import get_config\n",
    "from armscan_env.envs.rewards import anatomy_based_rwd\n",
    "from armscan_env.util.visualizations import show_slices\n",
    "\n",
    "config = get_config()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Simple Clustering and Linear Sweep Search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "volume = sitk.ReadImage(config.get_single_labelmap_path(1))\n",
    "volume_img = sitk.GetArrayFromImage(volume)\n",
    "print(f\"{volume_img.shape=}\")\n",
    "\n",
    "size = np.array(volume.GetSize()) * np.array(volume.GetSpacing())\n",
    "print(f\"{size=} mm\")\n",
    "transversal_extent = [0, size[0], 0, size[2]]\n",
    "longitudinal_extent = [0, size[1], 0, size[2]]\n",
    "frontal_extent = [0, size[0], size[1], 0]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we are going to explain the process of searching the carpal tunnel along one axis using a simple clustering algorithm. The first step is to visualize the data to understand the anatomy of the hand at the level of the carpal tunnel. We will then use a simple clustering algorithm to identify the number of features present in each image. Based on the number of features and their relative positions, we will be able to identify the carpal tunnel, basing on its anatomical description.\n",
    "\n",
    "Since we are not changing the orientation of the slices along the hand, we are bound to a sub-optimal visualization along the axis on which the images have been stacked. This is not exactly transversal to the carpal tunnel, so our anatomical description will be relative to this suboptimal orientation. However, we can still demonstrate that the anatomical description of the region of interest is enough to optimize the navigation.\n",
    "\n",
    "The following images are slices in proximity of the carpal tunnel area."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "show_slices(data=volume_img, start=690, end=20, lap=1, extent=transversal_extent)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of the labels are going to be used to identify the clusters of tissues and reason about the anatomy seen in the image."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "tissues = {\n",
    "    \"bones\": 1,\n",
    "    \"tendons\": 2,\n",
    "    \"ulnar\": 3,\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `cluster_iter` is going to be used to identify the clusters of tissues in the image. It iterates over the tissues in the dictionary and identifies the clusters of each tissue. The clustering algorithm uses a center-symmetric filter to identify clusters of neighboring pixels with the same value. The algorithm is based on the `label` function from the `scipy.ndimage` package. The function returns a dictionary with the clusters of tissues and the center of each of them."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from armscan_env.clustering import cluster_iter\n",
    "from armscan_env.util.visualizations import show_clusters\n",
    "\n",
    "clusters_679 = cluster_iter(tissues, volume_img[:, 679, :].T)\n",
    "fig = show_clusters(clusters_679, volume_img[:, 679, :].T, extent=transversal_extent)\n",
    "fig.set_xlabel(\"X [mm]\")\n",
    "fig.set_ylabel(\"Z [mm]\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing slices of the hand at different levels, is going to make clear why it is enough to reason about the anatomy of one slice to identify the region of interest.\n",
    "The function `anatomy_based_rwd` calculates the score of each image. This offers an observable reward, which can be used to optimize the navigation problem with classical search methods as well as with RL algorithms. The score is based on the number of clusters recognized for each tissue, which should be equal to the `n_landmarks` parameter. If some of the tissues are not present at all, this is more hardly penalized, because it means that the navigation is far off. Moreover, the score takes into account the position of the landmarks: in particular it checks whether the ulnar artery lies underneath the tendons clusters or not. The score is then normalized to sum up to one.\n",
    "\n",
    "We tuned the score function to our sub-optimal region of interest: it returns a zero loss for the slice showing the described anatomical conformation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "# Create a figure and a gridspec with two rows and two columns\n",
    "fig = plt.figure(constrained_layout=True, figsize=(12, 6))\n",
    "gs = fig.add_gridspec(2, 3)\n",
    "\n",
    "# Add subplots\n",
    "ax1 = fig.add_subplot(gs[:, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "ax4 = fig.add_subplot(gs[1, 1])\n",
    "ax5 = fig.add_subplot(gs[1, 2])\n",
    "\n",
    "\n",
    "ax1.axhline(y=418, color=\"red\", linestyle=\"--\", label=f\"Horizontal Line at Z-index = {418}\")\n",
    "ax1.axhline(y=601, color=\"red\", linestyle=\"--\", label=f\"Horizontal Line at Z-index = {601}\")\n",
    "ax1.axhline(y=679, color=\"red\", linestyle=\"--\", label=f\"Horizontal Line at Z-index = {679}\")\n",
    "ax1.axhline(y=739, color=\"red\", linestyle=\"--\", label=f\"Horizontal Line at Z-index = {739}\")\n",
    "ax1.imshow(volume_img[35, :, :], label=\"Hand\")\n",
    "ax1.set_xlabel(\"x: pixels\")\n",
    "ax1.set_ylabel(\"z: pixels\")\n",
    "ax1.legend()\n",
    "\n",
    "clusters_418 = cluster_iter(tissues, volume_img[:, 418, :].T)\n",
    "show_clusters(clusters_418, volume_img[:, 418, :].T, ax2, extent=transversal_extent)\n",
    "reward_418 = anatomy_based_rwd(clusters_418, n_landmarks=(7, 5, 1))\n",
    "ax2.text(\n",
    "    0.95,\n",
    "    0.1,\n",
    "    f\"Reward: {reward_418:.2f}\",\n",
    "    horizontalalignment=\"right\",\n",
    "    verticalalignment=\"bottom\",\n",
    "    transform=ax2.transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5, edgecolor=\"black\", boxstyle=\"round,pad=1\"),\n",
    ")\n",
    "ax2.set_title(\"Slice 418\")\n",
    "ax2.axis(\"off\")\n",
    "\n",
    "clusters_601 = cluster_iter(tissues, volume_img[:, 601, :].T)\n",
    "show_clusters(clusters_601, volume_img[:, 601, :].T, ax3, extent=transversal_extent)\n",
    "reward_601 = anatomy_based_rwd(clusters_601, n_landmarks=(7, 5, 1))\n",
    "ax3.text(\n",
    "    0.95,\n",
    "    0.1,\n",
    "    f\"Reward: {reward_601:.2f}\",\n",
    "    horizontalalignment=\"right\",\n",
    "    verticalalignment=\"bottom\",\n",
    "    transform=ax3.transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5, edgecolor=\"black\", boxstyle=\"round,pad=1\"),\n",
    ")\n",
    "ax3.set_title(\"Slice 601\")\n",
    "ax3.axis(\"off\")\n",
    "\n",
    "show_clusters(clusters_679, volume_img[:, 679, :].T, ax4, extent=transversal_extent)\n",
    "reward_679 = anatomy_based_rwd(clusters_679, n_landmarks=(7, 5, 1))\n",
    "ax4.text(\n",
    "    0.95,\n",
    "    0.1,\n",
    "    f\"Reward: {reward_679:.2f}\",\n",
    "    horizontalalignment=\"right\",\n",
    "    verticalalignment=\"bottom\",\n",
    "    transform=ax4.transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5, edgecolor=\"black\", boxstyle=\"round,pad=1\"),\n",
    ")\n",
    "ax4.set_title(\"Slice 679\")\n",
    "ax4.axis(\"off\")\n",
    "\n",
    "clusters_739 = cluster_iter(tissues, volume_img[:, 739, :].T)\n",
    "show_clusters(clusters_739, volume_img[:, 739, :].T, ax5, extent=transversal_extent)\n",
    "reward_739 = anatomy_based_rwd(clusters_739, n_landmarks=(7, 5, 1))\n",
    "ax5.text(\n",
    "    0.95,\n",
    "    0.1,\n",
    "    f\"Reward: {reward_739:.2f}\",\n",
    "    horizontalalignment=\"right\",\n",
    "    verticalalignment=\"bottom\",\n",
    "    transform=ax5.transAxes,\n",
    "    bbox=dict(facecolor=\"white\", alpha=0.5, edgecolor=\"black\", boxstyle=\"round,pad=1\"),\n",
    ")\n",
    "ax5.set_title(\"Slice 739\")\n",
    "ax5.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The clustering algorithm does not just give us information about the number of tissues clusters, but also about their position. Hence, it is possible to reason about the orientation of the image and the relation of the tissues to one another."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "clusters_679 = cluster_iter(tissues, volume_img[:, 679, :].T)\n",
    "\n",
    "bones_centers = [cluster.center for _, cluster in enumerate(clusters_679.bones)]\n",
    "ligament_centers = [cluster.center for _, cluster in enumerate(clusters_679.tendons)]\n",
    "\n",
    "bones_center = np.mean(bones_centers, axis=0)\n",
    "print(\"bones_center: \", bones_center)\n",
    "ligament_center = np.mean(ligament_centers, axis=0)\n",
    "print(\"ligament_center: \", ligament_center)\n",
    "ulnar_center = clusters_679.ulnar[0].center\n",
    "print(\"ulnar_center: \", ulnar_center)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "anatomy_based_rwd(clusters_679, n_landmarks=(7, 5, 1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performing a linear sweep search along the axis of the hand, we can identify the optimal region that returns a zero loss. We can also see that the loss converges to zero as we approach the optimal region."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "source": [
    "sweep_loss = []\n",
    "zero_loss_clusters = []\n",
    "\n",
    "for i in range(volume_img.shape[1]):\n",
    "    clusters = cluster_iter(tissues, volume_img[:, i, :].T)\n",
    "    loss = anatomy_based_rwd(clusters, n_landmarks=(7, 5, 1))\n",
    "    sweep_loss.append(loss)\n",
    "    if loss == 0:\n",
    "        zero_loss_clusters.append(clusters)\n",
    "    print(f\"Loss for slice {i}: {sweep_loss[i]}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "plt.plot(range(len(sweep_loss)), sweep_loss, marker=\"o\")\n",
    "\n",
    "plt.xlabel(\"Slice index\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Score along axial slices\")\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize the slices that return a zero loss to check whether this approach is valid."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "zero_loss_indices = np.where(np.array(sweep_loss) == 0)[0]\n",
    "print(f\"{len(zero_loss_indices)} indices return a zero loss: \", zero_loss_indices)\n",
    "\n",
    "nrows = 1\n",
    "ncols = len(zero_loss_indices) // nrows\n",
    "indices_to_display = nrows * ncols\n",
    "\n",
    "if indices_to_display > 0:\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(20, 10))\n",
    "    axes = axes.flatten()\n",
    "    for i, idx in enumerate(zero_loss_indices[:indices_to_display]):\n",
    "        axes[i] = show_clusters(\n",
    "            tissue_clusters=zero_loss_clusters[i],\n",
    "            slice=volume_img[:, idx, :].T,\n",
    "            extent=transversal_extent,\n",
    "            aspect=2,\n",
    "            ax=axes[i],\n",
    "        )\n",
    "        axes[i].set_title(f\"Index: {idx}, Loss: {sweep_loss[idx]:.2f}\")\n",
    "        axes[i].axis(\"off\")\n",
    "\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the results are quite promising, but the clustering algorithm is not really identifying the clusters robustly. There are some clusters that are not separated because they have connected pixels. Moreover, it is not possible to tune the clustering algorithm for an expected size, preventing outliers to be detected."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "clusters_668 = cluster_iter(tissues, volume_img[:, 668, :].T)\n",
    "show_clusters(clusters_668, volume_img[:, 668, :].T, extent=transversal_extent, aspect=2)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In the next notebook, we will show the performance using a different clustering algorithm."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
