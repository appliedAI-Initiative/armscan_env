{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment, all in one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from armscan_env.clustering import TissueClusters\n",
    "from armscan_env.config import get_config\n",
    "from armscan_env.envs.labelmaps_navigation import (\n",
    "    LabelmapClusteringBasedReward,\n",
    "    LabelmapEnv,\n",
    "    LabelmapEnvTerminationCriterion,\n",
    ")\n",
    "from armscan_env.envs.observations import (\n",
    "    ActionRewardObservation,\n",
    "    LabelmapSliceAsChannelsObservation,\n",
    ")\n",
    "from armscan_env.envs.rewards import anatomy_based_rwd\n",
    "from armscan_env.envs.state_action import ManipulatorAction\n",
    "from armscan_env.util.visualizations import show_clusters\n",
    "from armscan_env.volumes.loading import load_sitk_volumes\n",
    "from celluloid import Camera\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now put everything together in a single environment. We will use the `get_volume_slice` function to create a 2D slice of the 3D volume, and then we will use the `find_DBSCAN_clusters` function to find the clusters of pixels that correspond to the different tissues. Finally, we will use the `anatomy_based_rwd` function to calculate the reward based on the anatomy of the arm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes = load_sitk_volumes(normalize=True)\n",
    "img_array_1 = sitk.GetArrayFromImage(volumes[0])\n",
    "img_array_2 = sitk.GetArrayFromImage(volumes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "t = [160, 155, 150, 148, 146, 142, 140, 140, 115, 120, 125, 125, 130, 130, 135, 138, 140, 140, 140]\n",
    "z = [0, -5, 0, 0, 5, 15, 19.3, -10, 0, 0, 0, 5, -8, 8, 0, -10, -10, 10, 19.3]\n",
    "o = volumes[0].GetOrigin()\n",
    "slice_shape = (volumes[0].GetSize()[0], volumes[0].GetSize()[2])\n",
    "\n",
    "\n",
    "# Sample functions for demonstration\n",
    "def linear_function(x: np.ndarray, m: float, b: float) -> np.ndarray:\n",
    "    return m * x + b\n",
    "\n",
    "\n",
    "# Create a figure and a gridspec with two rows and two columns\n",
    "fig = plt.figure(constrained_layout=True, figsize=(8, 6))\n",
    "gs = fig.add_gridspec(2, 2)\n",
    "camera = Camera(fig)\n",
    "\n",
    "# Add subplots\n",
    "ax1 = fig.add_subplot(gs[:, 0])\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "for i in range(len(t)):\n",
    "    # Subplot 1: Image with dashed line\n",
    "    ax1.imshow(img_array_1[40, :, :])\n",
    "    x_dash = np.arange(img_array_1.shape[2])\n",
    "    b = volumes[0].TransformPhysicalPointToIndex([o[0], o[1] + t[i], o[2]])[1]\n",
    "    y_dash = linear_function(x_dash, np.tan(np.deg2rad(z[i])), b)\n",
    "    ax1.set_title(f\"Section {0}\")\n",
    "    line = ax1.plot(x_dash, y_dash, linestyle=\"--\", color=\"red\")[0]\n",
    "    ax1.set_title(\"Slice cut\")\n",
    "\n",
    "    # ACTION\n",
    "    sliced_volume = volumes[0].get_volume_slice(\n",
    "        slice_shape=slice_shape,\n",
    "        action=ManipulatorAction(rotation=(z[i], 0.0), translation=(0.0, t[i])),\n",
    "    )\n",
    "    sliced_img = sitk.GetArrayFromImage(sliced_volume).T\n",
    "    ax2.imshow(sliced_img.T, aspect=6, origin=\"lower\")\n",
    "    ax2.set_title(f\"Slice {i}\")\n",
    "\n",
    "    # OBSERVATION\n",
    "    clusters = TissueClusters.from_labelmap_slice(sliced_img)\n",
    "    ax3 = show_clusters(clusters, sliced_img, ax3)\n",
    "    ax3.set_title(f\"Clusters {i}\")\n",
    "\n",
    "    # REWARD\n",
    "    loss = anatomy_based_rwd(clusters)\n",
    "    ax3.text(0, 0, f\"Loss: {loss:.2f}\", fontsize=12, color=\"red\")\n",
    "\n",
    "    camera.snap()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "animation = camera.animate()\n",
    "HTML(animation.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rotations are defined in degrees, and translations are defined in millimeters. In order for the agent to take meaningful actions, we need to define the action space by bounds. Rotation bounds are set to 180 degrees, since a greater angle can be achieved by rotating in the opposite direction. Translation bounds are set to stay within the image bounds.\n",
    "The physical dimension of the volume is expressed in mm. It is calculated by taking the difference between the physical coordinates of the first and last voxel in the volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = volumes[0].GetOrigin()\n",
    "spacing = volumes[0].GetSpacing()\n",
    "size = volumes[0].GetSize()\n",
    "end = volumes[0].TransformIndexToPhysicalPoint(size)\n",
    "print(f\"{origin=},\\n {spacing=},\\n {end=}\")\n",
    "dim = np.subtract(end, origin)\n",
    "physical_size = size * np.array(spacing)\n",
    "index_dim = dim / spacing\n",
    "print(f\"{dim=} == {physical_size},\\n {index_dim=} == {size=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_size = volumes[0].GetSize()\n",
    "\n",
    "env = LabelmapEnv(\n",
    "    name2volume={\"1\": volumes[0], \"2\": volumes[1]},\n",
    "    observation=LabelmapSliceAsChannelsObservation(\n",
    "        slice_shape=(volume_size[0], volume_size[2]),\n",
    "        action_shape=(4,),\n",
    "    ),\n",
    "    slice_shape=(volume_size[0], volume_size[2]),\n",
    "    reward_metric=LabelmapClusteringBasedReward(),\n",
    "    termination_criterion=LabelmapEnvTerminationCriterion(),\n",
    "    max_episode_len=10,\n",
    "    rotation_bounds=(30.0, 10.0),\n",
    "    translation_bounds=(None, None),\n",
    "    render_mode=\"animation\",\n",
    "    apply_volume_transformation=True,\n",
    ")\n",
    "\n",
    "observation, info = env.reset()\n",
    "for _ in range(50):\n",
    "    action = env.action_space.sample()\n",
    "    epsilon = 0.1\n",
    "    if np.random.rand() > epsilon:\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "    else:\n",
    "        observation, reward, terminated, truncated, info = env.step_to_optimal_state()\n",
    "    env.render()\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset(reset_render=False)\n",
    "animation = env.get_cur_animation()\n",
    "env.close()\n",
    "HTML(animation.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume_size = volumes[0].GetSize()\n",
    "\n",
    "env = LabelmapEnv(\n",
    "    name2volume={\"1\": volumes[6]},\n",
    "    observation=ActionRewardObservation(action_shape=(2,)).to_array_observation(),\n",
    "    slice_shape=(volume_size[0], volume_size[2]),\n",
    "    reward_metric=LabelmapClusteringBasedReward(),\n",
    "    termination_criterion=LabelmapEnvTerminationCriterion(min_reward_threshold=-0.05),\n",
    "    max_episode_len=10,\n",
    "    rotation_bounds=(30.0, 10.0),\n",
    "    translation_bounds=(None, None),\n",
    "    render_mode=\"animation\",\n",
    "    project_actions_to=\"zy\",\n",
    "    apply_volume_transformation=True,\n",
    ")\n",
    "\n",
    "observation, info = env.reset()\n",
    "for _ in range(50):\n",
    "    action = env.action_space.sample()\n",
    "    epsilon = 0.1\n",
    "    if np.random.rand() > epsilon:\n",
    "        observation, reward, terminated, truncated, info = env.step(action)\n",
    "    else:\n",
    "        observation, reward, terminated, truncated, info = env.step_to_optimal_state()\n",
    "    env.render()\n",
    "\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset(reset_render=False)\n",
    "animation = env.get_cur_animation()\n",
    "env.get_cur_animation_as_html()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
