{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import SimpleITK as sitk\n",
    "from armscan_env.clustering import TissueClusters\n",
    "from armscan_env.config import get_config\n",
    "from armscan_env.envs.rewards import anatomy_based_rwd\n",
    "from armscan_env.envs.state_action import ManipulatorAction\n",
    "from armscan_env.util.visualizations import show_clusters\n",
    "from armscan_env.volumes.volumes import ImageVolume\n",
    "from celluloid import Camera\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "config = get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arbitrary Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volume = sitk.ReadImage(config.get_single_labelmap_path(1))\n",
    "volume_img = sitk.GetArrayFromImage(volume)\n",
    "\n",
    "volume_size = volume.GetSize()\n",
    "img_size = volume_img.shape\n",
    "volume_origin = volume.GetOrigin()\n",
    "\n",
    "physical_size = np.array(volume.GetSize()) * np.array(volume.GetSpacing())\n",
    "print(f\"{volume_size=}\")\n",
    "print(f\"{img_size=}\")\n",
    "print(f\"{physical_size=} mm\")\n",
    "transversal_extent = [0, physical_size[0], 0, physical_size[2]]\n",
    "longitudinal_extent = [0, physical_size[1], 0, physical_size[2]]\n",
    "frontal_extent = [0, physical_size[0], physical_size[1], 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, we have only been able to visualize slices of the volume in the original orientation at which they were taken in the scan, and we defined a suboptimal view to visualize the carpal tunnel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_num = 670\n",
    "slice_ = volume_img[:, slice_num, :]\n",
    "plt.imshow(slice_, aspect=6)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is necessary to view arbitrary planes of the volume, in order to be able to view the optimal plane, regardless of the orientation of the original scanned slices. In this notebook we are going to present a re-slicing algorithm to take arbitrary slices of the 3D volume. To do this, we can make use of the `Euler3DTransform` class from SimpleITK, which allows us to define a transformation matrix to reference our new plane, and `Resaple`, which samples the slice as a new image out of the original volume.\n",
    "We need to define a Rotation matrix, a translation matrix, and the center of rotation, from which the transformation will be applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin = np.array(volume.GetOrigin())\n",
    "th_z = np.deg2rad(20)\n",
    "th_x = np.deg2rad(0)\n",
    "x_trans = 0\n",
    "y_trans = 140\n",
    "\n",
    "transform = sitk.Euler3DTransform()\n",
    "transform.SetRotation(th_x, 0, th_z)\n",
    "transform.SetTranslation((x_trans, y_trans, 0))\n",
    "transform.SetCenter(origin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need to define the resampling method, passing the volume we want to transform, the transformation matrix, and the interpolation method, which is set to nearest neighbor to preserve the integrity of the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_volume = sitk.Resample(\n",
    "    volume,\n",
    "    transform,\n",
    "    sitk.sitkNearestNeighbor,\n",
    "    0.0,\n",
    "    volume.GetPixelID(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have created a reference frame for the plane we want to extract. We now need to sample the slice. Since the output is supposed to be a volume, we take a three dimensional slice, basically a stack of two images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampler = sitk.ResampleImageFilter()\n",
    "resampler.SetReferenceImage(slice_volume)\n",
    "resampler.SetSize((volume_size[0], 2, volume_size[2]))\n",
    "resampler.SetInterpolator(sitk.sitkNearestNeighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now finally view the slice, just by plotting one of the 2D resampled images we have extracted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = resampler.Execute(slice_volume)[:, 0, :]\n",
    "slice_img = sitk.GetArrayFromImage(slice)\n",
    "print(f\"{slice_img.shape=}\")\n",
    "plt.imshow(slice_img, aspect=6)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of this is integrated in the `ImageVolume` class, which is a wrapper of the SimpleITK `Image` class, extended by the function `get_volume_slice` and by the attribute `optimal_action`, which permits to store the optimal rotation and translation parameters to view the standard plane of the carpal tunnel:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_volume = ImageVolume(\n",
    "    volume,\n",
    "    optimal_action=ManipulatorAction(rotation=(19.3, 0), translation=(0, 140)),\n",
    ")\n",
    "sliced_volume = image_volume.get_volume_slice(\n",
    "    action=image_volume.optimal_action,\n",
    "    slice_shape=(image_volume.GetSize()[0], image_volume.GetSize()[2]),\n",
    ")\n",
    "slice_img = sitk.GetArrayFromImage(sliced_volume)\n",
    "print(f\"Slice value range: {np.min(slice_img)} - {np.max(slice_img)}\")\n",
    "\n",
    "print(slice_img.shape)\n",
    "plt.imshow(slice_img, aspect=6)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform clustering on the optimal image and see if it results in an optimal score, which is fulfilled under the threshold $\\delta=0.05$:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = TissueClusters.from_labelmap_slice(slice_img.T)\n",
    "show_clusters(clusters, slice_img.T)\n",
    "reward = anatomy_based_rwd(clusters)\n",
    "print(f\"{reward=}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now look at the beauty of this new slicing method by defining arbitrary transformations:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration of arbitrary slicing\n",
    "# y-translations\n",
    "t = [160, 155, 150, 148, 146, 142, 140, 140, 115, 120, 125, 125, 130, 130, 135, 138, 140, 140, 140]\n",
    "# z-rotations\n",
    "z = [0, -5, 0, 0, 5, 15, 19.3, -10, 0, 0, 0, 5, -8, 8, 0, -10, -10, 10, 19.3]\n",
    "\n",
    "# Create figure and subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 6))\n",
    "camera = Camera(fig)\n",
    "o = volume_origin\n",
    "\n",
    "\n",
    "# Sample functions for demonstration\n",
    "def linear_function(x: np.ndarray, m: float, b: float) -> np.ndarray:\n",
    "    return m * x + b\n",
    "\n",
    "\n",
    "for i in range(len(t)):\n",
    "    # Subplot 1: Image with dashed line\n",
    "    ax1.imshow(volume_img[40, :, :], extent=frontal_extent)\n",
    "    x_dash = np.arange(physical_size[0])\n",
    "    b = o[1] + t[i]\n",
    "    y_dash = linear_function(x_dash, np.tan(np.deg2rad(z[i])), b)\n",
    "    ax1.set_title(f\"Section {i}\")\n",
    "    ax1.plot(x_dash, y_dash, linestyle=\"--\", color=\"red\")\n",
    "\n",
    "    # Subplot 2: Function image\n",
    "    sliced_volume = image_volume.get_volume_slice(\n",
    "        slice_shape=(image_volume.GetSize()[0], image_volume.GetSize()[2]),\n",
    "        action=ManipulatorAction(\n",
    "            rotation=(z[i], 0),\n",
    "            translation=(0, t[i]),\n",
    "        ),\n",
    "    )\n",
    "    sliced_img = sitk.GetArrayFromImage(sliced_volume)\n",
    "    ax2.set_title(f\"Slice {i}\")\n",
    "    ax2.imshow(sliced_img, aspect=6)\n",
    "    ax2.axis(\"off\")\n",
    "    camera.snap()\n",
    "    plt.close()\n",
    "\n",
    "animation = camera.animate()\n",
    "HTML(animation.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Hard Way\n",
    "\n",
    "This can be done in a harder way, if you want to define the transformations yourself. This is actually the original way the function was developed, before coming across the SimpleITK Euler3DTransform class, and it might still be useful for integration with different software.\n",
    "The first step is to define an Euler transformation with the angles of rotation and the array of translation. This transformation matrix simulates the position and orientation of an ultrasound probe, scanning the arm to get a 2D image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euler's transformation\n",
    "# Rotation is defined by three rotations around z1, x2, z2 axis\n",
    "th_z = np.deg2rad(20)\n",
    "th_x = np.deg2rad(0)\n",
    "x_trans = 0\n",
    "y_trans = 140\n",
    "\n",
    "# Translation vector\n",
    "o = np.array(volume_origin)\n",
    "\n",
    "# transformation simplified at th_y=0 since this rotation is never performed\n",
    "eul_tr = np.array(\n",
    "    [\n",
    "        [np.cos(th_z), -np.sin(th_z) * np.cos(th_x), np.sin(th_z) * np.sin(th_x), o[0] + x_trans],\n",
    "        [np.sin(th_z), np.cos(th_z) * np.cos(th_x), -np.cos(th_z) * np.sin(th_x), o[1] + y_trans],\n",
    "        [0, np.sin(th_x), np.cos(th_x), o[2]],\n",
    "        [0, 0, 0, 1],\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we define the coordinate system of the plane of the slice to take. The x and y coordinates are defined by the first two columns of the transformation matrix, and the normal vector of the plane is defined by the third column. The origin of the plane is defined by the last column of the transformation matrix, hence the translation from the image origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define plane's coordinate system\n",
    "e1 = eul_tr[0][:3]  # x-coordinate of image plane\n",
    "e2 = eul_tr[1][:3]  # y-coordinate of image plane\n",
    "e3 = eul_tr[2][:3]  # normal vector of image plane\n",
    "origin = eul_tr[:, -1:].flatten()[:3]  # origin of the image plane\n",
    "\n",
    "print(f\" {e1=},\\n {e2=},\\n {e3=},\\n {origin=}\")\n",
    "\n",
    "# Direction for the resampler will be (e1, e2, e3) flattened\n",
    "direction = np.stack([e1, e2, e3], axis=0).flatten()\n",
    "print(f\" {direction=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "he dimension of the new image will be set equal to the dimension of the images in the original transversal plane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = volume_size[2]  # height of the image plane: original z size\n",
    "w = volume_size[0]  # width of the image plane: original x size\n",
    "\n",
    "print(f\" {h=},\\n {w=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use SimpleITK's resampler to take the slice of the volume. We set the output direction, origin, and spacing to the ones defined by the plane. The size of the output image is defined by the width and height of the plane, and has a depth of 3 for visualization purposes when fed back into a volume renderer like ImFusion. The interpolator is set to nearest neighbor, since our label space is discrete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SimpleITK's resampler\n",
    "resampler = sitk.ResampleImageFilter()\n",
    "# Extract properties from the SimpleITK Image\n",
    "spacing = volume.GetSpacing()\n",
    "\n",
    "# use reference image\n",
    "resampler.SetOutputDirection(direction.tolist())\n",
    "resampler.SetOutputOrigin(origin.tolist())\n",
    "resampler.SetOutputSpacing(spacing)\n",
    "resampler.SetSize((w, 3, h))\n",
    "resampler.SetInterpolator(sitk.sitkNearestNeighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the resampler is a 3D image, which we can convert to a numpy array and visualize. We can check that the value range corresponds to that of the labelmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sliced_volume = resampler.Execute(volume)\n",
    "sliced_img = sitk.GetArrayFromImage(sliced_volume)\n",
    "\n",
    "print(f\"Slice value range: {np.min(sliced_img)} - {np.max(sliced_img)}\")\n",
    "print(f\" {sliced_volume.GetSize()=},\\n {volume_size=},\\n {sliced_img.shape=},\\n {img_size=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to save the image has a .nii file for further visualization on a volume renderer. You can do this locally as follows:\n",
    "```python\n",
    "output_path = os.path.join(\"../..\", \"data\", \"outputs\", \"sliced_volume.nii.gz\")\n",
    "sitk.WriteImage(sliced_volume, output_path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualize the slice in a new orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice = sliced_img[:, 0, :]\n",
    "plt.imshow(slice, aspect=6)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_im",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
